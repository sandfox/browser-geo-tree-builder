// Generated by CoffeeScript 1.4.0

/*
Really Hacky Script to generate the kdtree and record files
usage  $ bin/csv2GeoJSON {ARGS}

look at https://gist.github.com/85f5ab526a9158b2cd30 for a hint on how to use this

TODO :	allow this output straight to gzip
		use ssmaller datasctructure and publish entire package for browsers
		move the kdtree into it's own npm module
*/


(function() {
  var KDTree, argv, columnLayout, csv, endHandler, errorHandler, fmt, fs, headerHandler, lingo, parser, path, points, precision, recordHandler, stats;

  fs = require('fs');

  csv = require('csv');

  path = require('path');

  KDTree = require('../kdtree');

  fmt = require('fmt');

  lingo = require('lingo');

  argv = require('optimist').usage(fmt.sep(), +fmt.field('program', 'csv2json'), +fmt.field('desc', 'produce index.json and json files for every record based upon input CSV'), +fmt.field('version', require('../package.json').version)).demand(['f', 'o']).alias({
    'f': 'file',
    'o': 'out',
    's': 'single',
    'p': 'precision',
    'u': 'attempt to de-uglify field names from the csv, default yes'
  }).describe({
    'f': 'The CSV to parse',
    'o': 'the folder to output the records to',
    's': 'Output json in single file rather than index + records [bool]',
    'p': 'number of decimal places to store lat/lons as, default 4'
  }).argv;

  points = [];

  columnLayout = {
    x: null,
    y: null,
    other: []
  };

  stats = {
    skippedRows: 0
  };

  errorHandler = function(err) {
    fmt.separator();
    fmt.dump(err, 'Error');
    return process.exit();
  };

  headerHandler = function(record, index) {
    var col, prettyCol, _i, _len;
    if (record.indexOf('latitude' !== -1)) {
      columnLayout.y = record.indexOf('latitude');
    }
    if (record.indexOf('longitude' !== -1)) {
      columnLayout.x = record.indexOf('longitude');
    }
    if (!(columnLayout.y != null) || !(columnLayout.x != null)) {
      fmt.field('Error', 'No header column found for latitude and/or longitude');
      process.exit();
    }
    fmt.sep();
    fmt.field('Total Header Columns', record.length);
    for (index = _i = 0, _len = record.length; _i < _len; index = ++_i) {
      col = record[index];
      if (col) {
        prettyCol = lingo.camelcase(col.toLowerCase());
        columnLayout.other[prettyCol] = index;
        fmt.subfield(prettyCol, index + (" [" + col + "]"));
      }
    }
    fmt.field('Columns skipped', record.length - Object.keys(columnLayout.other).length);
    parser.removeListener('record', headerHandler);
    return parser.on('record', recordHandler);
  };

  recordHandler = function(record, index) {
    var col, i, struct, tmpRecord, x, y, _ref;
    if ((record[columnLayout.x] != null) && (record[columnLayout.y] != null)) {
      x = parseFloat(record[columnLayout.x]);
      y = parseFloat(record[columnLayout.y]);
    } else {
      stats.skippedRows++;
      null;
    }
    tmpRecord = {};
    _ref = columnLayout.other;
    for (col in _ref) {
      i = _ref[col];
      tmpRecord[col] = record[i];
    }
    if (!argv.single) {
      fs.writeFileSync(path.join(argv.out, index + ".json"), JSON.stringify(tmpRecord));
    }
    struct = {
      x: x.toFixed(precision),
      y: y.toFixed(precision),
      id: index
    };
    if (argv.single) {
      struct.data = tmpRecord;
    }
    points.push(struct);
    return null;
  };

  endHandler = function(count) {
    fmt.sep();
    fmt.title("Processing finished");
    fmt.field("Rows proccessed", count);
    fmt.field("Rows skipped", stats.skippedRows);
    return fs.writeFileSync(path.join(argv.out, "index.json"), JSON.stringify(new KDTree(points)));
  };

  if (!fs.statSync(argv.out).isDirectory()) {
    fmt.field('Error', 'output folder appears not to be a folder');
    process.exit();
  }

  precision = argv.precision != null ? argv.precision : 4;

  parser = csv().from.stream(fs.createReadStream(argv.file)).on('error', errorHandler).on('record', headerHandler).on('end', endHandler);

}).call(this);
